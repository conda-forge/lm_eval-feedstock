context:
  name: lm_eval
  version: 0.4.5

package:
  name: ${{ name|lower }}
  version: ${{ version }}

source:
  url: https://pypi.io/packages/source/${{ name[0] }}/${{ name }}/lm_eval-${{ version }}.tar.gz
  sha256: f5c28b6fdb838bd052037419addbf14b8de47e786390dd98fbfbf8e23c1b6155

build:
  number: 0
  skip:
    - win
  script: python -m pip install . -vv --no-deps --no-build-isolation

requirements:
  build:
    - ${{ compiler('cxx') }}
    - ${{ stdlib("c") }}
  host:
    - python
    - pip
    - setuptools
  run:
    - python
    - datasets >=2.0.0
    - evaluate
    - jsonlines
    - numexpr
    - openai >=0.6.4
    - peft
    - pybind11 >=2.6.2
    - pycountry
    - pytablewriter
    - rouge-score >=0.0.4
    - sacrebleu ==1.5.0
    - scikit-learn >=0.24.1
    - sqlitedict
    - pytorch >=1.7
    - tqdm-multiprocess
    - transformers >=4.1
    - zstandard
    - more-itertools
    - word2number

tests:
  - python:
      imports:
        - lm_eval
      pip_check: true
  - requirements:
    script:
      - lm_eval -h

about:
  summary: A framework for evaluating autoregressive language models
  license: MIT
  license_file: LICENSE.md
  homepage: https://github.com/EleutherAI/lm-evaluation-harness

extra:
  recipe-maintainers:
    - mediocretech
